{
    "collab_server" : "",
    "contents" : "dataset <- read.csv(\"/home/heru/Desktop/Mydata3.csv\", \n                      header = TRUE, \n                      sep = \",\")\n\nstr(dataset)\n#Berapa Jumlah yang disengeketakan?\nsummary(dataset$Class)\n\nlibrary(caret)\n#Training, validation and test data\n\nset.seed(42)\nindex <- createDataPartition(dataset$Class, p = 0.7, list = FALSE)\ntrain_data <- dataset[index, ]\ntest_data  <- dataset[-index, ]\n\n\n#Classification\n#Decision trees\nlibrary(rpart)\nlibrary(rpart.plot)\n\nset.seed(42)\nfit <- rpart(Class ~ .,\n             data = train_data,\n             method = \"class\",\n             control = rpart.control(xval = 10, \n                                     minbucket = 2, \n                                     cp = 0), \n             parms = list(split = \"information\"))\n\n\nrpart.plot(fit)\n\npre1<-predict(fit, test_data, type = \"class\")\nconfusionMatrix(pre1,test_data$Class)\n\nlibrary(MLmetrics)\nlibrary(ROCR)\nF1_score<- F1_Score(test_data$Class, pre1, positive = NULL)\nF1_score\n\nprec<-predict(fit, test_data, type = \"matrix\")\npra<-prec[,6]\nlength(pra)\nlength(test_data$Class)\n\ntest_data$Class<-as.numeric(test_data$Class)\ntest_data$Class<-ifelse(test_data$Class==2,1,0)\ntest_data$Class\npredroc <- prediction(predictions = prec[,6], labels=test_data$Class)\npredroc\nroc<-performance(predroc,\"tpr\", \"fpr\")\nplot(roc)\n\n# And then a lift chart\nperf <- performance(predroc,\"lift\",\"rpp\")\nplot(perf, main=\"lift curve\", colorize=T)\n\nlibrary(ROCR)\ngain.chart <- function(n) {\n  score <- runif(n)\n  y <- (runif(n) < score)\n  plot(performance(prediction(score, y), “tpr”, “rpp”),lwd = 7, main = paste(“N =”, n))\n  lines(ecdf((rank(-score)[y == T]) / n),verticals = T, do.points = F, col = “red”, lwd = 3)\n}\n\nset.seed(1)\npar(mfrow = c(1, 2))\ngain.chart(10)\ngain.chart(10000)\n\n\n\n\nLift<-LiftAUC(test_data$Class, predroc)\nLogLos1<-LogLoss(test_data$Class, pra)\nLogLos1\nKSS<-KS_Stat(test_data$Class, pra)\nKSS\nGini(test_data$Class, pra)\n\n\nwarnings()\nlibrary(ROCR)\nytest<-test_data$Disengketakan\nprec<-predict(fit, test_data, type = \"prob\")\npredroc <- prediction(predictions = prec[,2], labels=ytest)\nroc<-performance(predroc,\"tpr\", \"fpr\")\nplot(roc, colorize=TRUE, main=\"ROC Curve\", xlab=\"Sensitivity\", ylab=\"1-Specifity\")\nabline(a=0, b=1, col=\"red\")\n#AUC\nauc<-performance(predroc,\"auc\")\nauc<-unlist(slot(auc, \"y.values\"))\nauc<-round(auc,4)\nlegend(.7, .5, auc, title=\"AUC\", cex=0.75)\n\n\n\n\n\n#Random Forest\nset.seed(42)\nlibrary(randomForest)\ntrain_data<-na.omit(train_data)\ndataset<-na.omit(dataset)\nrf<-randomForest(Disengketakan ~., dataset, ntree = 500,\n                 mtry = 2,\n                 importance = TRUE,\n                 proximity = TRUE)\n\nprint(rf)\nattributes(rf)\n\n\n# Prediction & Confusion Matrix - train data\nlibrary(caret)\np1 <- predict(rf, train_data)\nconfusionMatrix(p1, train_data$Disengketakan)\n\n# # Prediction & Confusion Matrix - test data\np2 <- predict(rf, test_data)\nconfusionMatrix(p2, test_data$Disengketakan)\n\n# Error rate of Random Forest\nplot(rf)\n\n# Tune mtry\nt <- tuneRF(train_data[,-5], train_data[,5],\n            stepFactor = 0.5,\n            plot = TRUE,\n            ntreeTry = 300,\n            trace = TRUE,\n            improve = 0.05)\n\nrf<-randomForest(Disengketakan ~., dataset, ntree = 500,\n                 mtry = 1,\n                 importance = TRUE,\n                 proximity = TRUE)\n\n# # Prediction & Confusion Matrix - test data\np2 <- predict(rf, test_data)\nconfusionMatrix(p2, test_data$Disengketakan)\n\n\n# No. of nodes for the trees\nhist(treesize(rf),\n     main = \"No. of Nodes for the Trees\",\n     col = \"green\")\n\n# Variable Importance\nvarImpPlot(rf,\n           sort = T,\n           main = \"Variable Importance\")\nimportance(rf)\nvarUsed(rf)\n\n\n# Extract Single Tree\ngetTree(rf, 1, labelVar = TRUE)\n\n# Multi-dimensional Scaling Plot of Proximity Matrix\n#MDSplot(rf, train_data$Churn)\n\n\n#Extreme gradient boosting trees\n#Install XGB\n#install.packages(\"drat\", repos=\"https://cran.rstudio.com\")\n#drat:::addRepo(\"dmlc\")\n#install.packages(\"xgboost\", repos=\"http://dmlc.ml/drat/\", type = \"source\")\nset.seed(42)\nlibrary(xgboost)\nmodel_xgb <- caret::train(Disengketakan ~ .,\n                          data = train_data,\n                          method = \"xgbTree\",\n                          preProcess = c(\"scale\", \"center\"),\n                          trControl = trainControl(method = \"repeatedcv\", \n                                                   number = 10, \n                                                   repeats = 10, \n                                                   savePredictions = TRUE, \n                                                   verboseIter = FALSE))\n#Feature Importance\nimportance <- varImp(model_xgb, scale = TRUE)\nplot(importance)\n\n\n#predicting test data\nconfusionMatrix(predict(model_xgb, test_data), test_data$Disengketakan)\n\nresults <- data.frame(actual = test_data$Disengketakan,predict(model_xgb, test_data, type = \"prob\"))\n\nlibrary(ROCR)\nytest<-test_data$Disengketakan\npred1<-predict(model_xgb, test_data, type = \"prob\")\npredroc <- prediction(predictions = pred1[,2], labels=ytest)\nroc<-performance(predroc,\"tpr\", \"fpr\")\nplot(roc, colorize=TRUE, main=\"ROC Curve\", xlab=\"Sensitivity\", ylab=\"1-Specifity\")\nabline(a=0, b=1, col=\"red\")\n#AUC\nauc<-performance(predroc,\"auc\")\nauc<-unlist(slot(auc, \"y.values\"))\nauc<-round(auc,4)\nlegend(.7, .5, auc, title=\"AUC\", cex=0.75)\n\n\nlibrary(neuralnet)\ntrain_data$Disengketakan<-as.numeric(train_data$Disengketakan)\ntrain_data$BentukInvoice<-as.numeric(train_data$BentukInvoice)\nset.seed(43)\nNnet <- neuralnet(train_data$Disengketakan ~ train_data$HariKeterlambatan + train_data$TenggatWaktu + train_data$NilaiInvoice + train_data$BentukInvoice, data=train_data, hidden = 5, learningrate=0.01)\nplot(Nnet, rep = \"best\")\n\n#testing the model on the test dataset\ntest_data$Disengketakan<-as.numeric(test_data$Disengketakan)\ntest_data$BentukInvoice<-as.numeric(test_data$BentukInvoice)\ntemp_test <- subset(test_data, select = c(\"HariKeterlambatan\", \"TenggatWaktu\", \"NilaiInvoice\", \"BentukInvoice\"))\narnet.results <- compute(Nnet, temp_test)\n\n#showing our predictor inputs within the test dataset\nhead(temp_test)\n\n#showing the difference between our predicted outcome and the actual outcome within our test data set.\nresults <- data.frame(actual = test_data$Disengketakan, prediction = arnet.results$net.result)\nresults[1:15, ]\n\narnet.results$net.result\n\n#This is a rounded result in order to make it easier to read.\nresults$prediction1 <- round(results$prediction)\nresults[1:15, ]\ntable(results$actual,results$prediction1)\nlibrary(caret)\nconfusionMatrix(results$actual,results$prediction1)\n\nprediction<-as.matrix(results$prediction)\nactual<-results$actual\n\n#ROCR\nlibrary(ROCR)\npred <-ROCR:: prediction(prediction, actual)\nperf <- performance(pred, measure=\"tpr\", x.measure=\"fpr\")\nroc<-performance(pred,\"tpr\", \"fpr\")\nplot(roc, colorize=TRUE, main=\"ROC Curve\", xlab=\"Sensitivity\", ylab=\"1-Specifity\")\nabline(a=0, b=1, col=\"black\")\n#AUC\n#AUC\nauc<-performance(pred,\"auc\")\nauc<-unlist(slot(auc, \"y.values\"))\nauc<-round(auc,4)\nlegend(.7, .5, auc, title=\"AUC\", cex=0.75)\n\n",
    "created" : 1492689864704.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1855767008",
    "id" : "C146646A",
    "lastKnownWriteTime" : 1492614289,
    "last_content_update" : 1492614289,
    "path" : "~/Desktop/ML AR INA.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}